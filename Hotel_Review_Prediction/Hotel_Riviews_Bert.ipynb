{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hotel_Riviews_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidriasat/Natural-Language-Processing/blob/master/Hotel_Review_Prediction/Hotel_Riviews_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ffn6UqsVI_t",
        "outputId": "4b7408f7-5128-4336-c444-cfe4d0f01aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/61/0b49baae16f482156550ce0b78a7ad265c27188a9d4fe6a1bd741fb43b9d/boto3-1.16.13.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Collecting botocore<1.20.0,>=1.19.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 14.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Building wheels for collected packages: boto3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.16.13-py2.py3-none-any.whl size=128453 sha256=7d006e87cfe9f9ae72c91fc6e410c5ddf75608cdb5acc9f1740ec06179e0cb37\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ca/cc/d99cff66806b87034af25f8fd8b0adb3e0151b17eea7891143\n",
            "Successfully built boto3\n",
            "\u001b[31mERROR: botocore 1.19.13 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.13 botocore-1.19.13 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsOPhGonjEPV"
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHn6asQ4kv-w"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip-ROaI4Hf3I",
        "outputId": "2934ec82-5969-41ae-f378-3d3825430622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://times.cs.uiuc.edu/~wang296/Data/LARA/TripAdvisor/TripAdvisorJson.tar.bz2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-07 06:27:50--  http://times.cs.uiuc.edu/~wang296/Data/LARA/TripAdvisor/TripAdvisorJson.tar.bz2\n",
            "Resolving times.cs.uiuc.edu (times.cs.uiuc.edu)... 192.17.58.170\n",
            "Connecting to times.cs.uiuc.edu (times.cs.uiuc.edu)|192.17.58.170|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 455746769 (435M) [application/x-bzip2]\n",
            "Saving to: ‘TripAdvisorJson.tar.bz2’\n",
            "\n",
            "TripAdvisorJson.tar 100%[===================>] 434.63M  55.3MB/s    in 9.2s    \n",
            "\n",
            "2020-11-07 06:28:00 (47.1 MB/s) - ‘TripAdvisorJson.tar.bz2’ saved [455746769/455746769]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB2M0cjQY-CN"
      },
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"TripAdvisorJson.tar.bz2\", \"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo6kmd_BZGS9"
      },
      "source": [
        "def replaceRating(rat):\n",
        "    num = 0\n",
        "    if(rat == \"0.0\" or rat == \"0\"):\n",
        "        num= 0\n",
        "    elif(rat == \"1.0\" or rat == \"1\"):\n",
        "        num= 1\n",
        "    elif(rat == \"2.0\" or rat == \"2\"):\n",
        "        num= 2\n",
        "    elif(rat == \"3.0\" or rat == \"3\"):\n",
        "        num= 3\n",
        "    elif(rat == \"4.0\" or rat == \"4\"):\n",
        "        num= 4\n",
        "    elif(rat == \"5.0\" or rat == \"5\"):\n",
        "        num= 5\n",
        "    return num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEWqdSa1ZJzw",
        "outputId": "8cf16a1e-78a2-41ba-a387-c0a15ef12ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Set the maximum sequence length. \n",
        "MAX_LEN = 200\n",
        "\n",
        "fileNames = os.listdir(\"json\")\n",
        "instances = [0,0,0,0,0,0]\n",
        "maxInstances = 1935\n",
        "contents= []\n",
        "ratings = []\n",
        "for fileName in fileNames:\n",
        "    with open((\"json/\"+fileName)) as file:\n",
        "        fileData = json.load(file)\n",
        "        for review in fileData[\"Reviews\"]:\n",
        "            if ('Content' in review and len(review['Content']) != 0 and 'Overall' in review[\"Ratings\"] and len(review[\"Ratings\"]['Overall']) != 0):\n",
        "                content = review[\"Content\"]\n",
        "                rating = review[\"Ratings\"][\"Overall\"]\n",
        "                rating = replaceRating(rating)\n",
        "                \n",
        "                if instances[rating] < maxInstances:\n",
        "                    ratings.append(rating)\n",
        "                    instances[rating] += 1\n",
        "\n",
        "                    templength= len(content.split() )\n",
        "                    if templength < MAX_LEN:\n",
        "                        contents.append(content)\n",
        "                    else:\n",
        "                        temp= \"\"\n",
        "                        convert= content.split()\n",
        "                        for j in range(0, MAX_LEN):\n",
        "                            temp= temp+ \" \"+convert[j]\n",
        "                        contents.append(temp)    \n",
        "                    \n",
        "\n",
        "    if (instances[0] + instances[1] + instances[2]+instances[3]+instances[4]+ instances[5]) >= (maxInstances*6):\n",
        "        break\n",
        "\n",
        "    \n",
        "print(len(contents))\n",
        "print(len(ratings))\n",
        "print(instances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11610\n",
            "11610\n",
            "[1935, 1935, 1935, 1935, 1935, 1935]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZxEJVFqkzve",
        "outputId": "e8a2ddcf-f45d-41af-f1ae-f0b27e1d1fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_X = contents\n",
        "data_Y= ratings\n",
        "\n",
        "\n",
        "print(len(data_X))\n",
        "print(len(data_Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11610\n",
            "11610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgnhGOh2lBYC"
      },
      "source": [
        "def extract_embed(data):\n",
        "    embedings=np.zeros((len(data),768))\n",
        "    cnt=0\n",
        "    for i in data:\n",
        "        # print(len(i.split()))\n",
        "        \n",
        "        # Add the special tokens.\n",
        "        marked_text = \"[CLS] \" +i+\" [SEP]\"\n",
        "\n",
        "        # Split the sentence into tokens.\n",
        "        tokenized_text = tokenizer.tokenize(marked_text)\n",
        "        #print (len(tokenized_text)\n",
        "        \n",
        "        # Map the token strings to their vocabulary indeces.\n",
        "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "        #print(indexed_tokens)\n",
        "        # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "        segments_ids = [1] * len(tokenized_text)\n",
        "        # Convert inputs to PyTorch tensors\n",
        "        tokens_tensor = torch.tensor([indexed_tokens])\n",
        "        segments_tensors = torch.tensor([segments_ids])\n",
        "        \n",
        "        # Predict hidden states features for each layer\n",
        "        with torch.no_grad():\n",
        "            encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "        # Concatenate the tensors for all layers. We use `stack` here to\n",
        "        # create a new dimension in the tensor.\n",
        "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "        # Remove dimension 1, the \"batches\".\n",
        "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "        # Swap dimensions 0 and 1.\n",
        "        token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "        # `token_vecs` is a tensor with shape [22 x 768]\n",
        "        token_vecs = encoded_layers[11][0]\n",
        "\n",
        "        # Calculate the average of all 22 token vectors.\n",
        "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "        \n",
        "        embedings[cnt]=sentence_embedding\n",
        "        cnt+=1\n",
        "        \n",
        "    return embedings\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaarP_PLlJ_-"
      },
      "source": [
        "X= extract_embed( data_X )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3fIgFOvvQfx",
        "outputId": "1a291349-e0d1-44de-a3d4-aba253cf857d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print( X.shape)\n",
        "print( type(X))\n",
        "Y= np.array(data_Y)\n",
        "print( Y.shape)\n",
        "print( type(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11610, 768)\n",
            "<class 'numpy.ndarray'>\n",
            "(11610,)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arn2E-WYvrf_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.15)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CMGFLVWvuuS",
        "outputId": "a56191a5-8009-40b8-c119-0659a17cb4d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = SVC(kernel='linear')\n",
        "# classifier = LogisticRegression(max_iter= 1000)\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT3_Zv-9vxlb"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGgMiksv1AJ",
        "outputId": "be29b559-94ef-4571-dd22-7f8d676f0a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[297   0   0   0   0   1]\n",
            " [  0 187  70  17   3   3]\n",
            " [  1  84 125  60  10   2]\n",
            " [  2  17  64 120  52  17]\n",
            " [  0   5  12  69 153  65]\n",
            " [  3   3   4  11  89 196]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       298\n",
            "           1       0.63      0.67      0.65       280\n",
            "           2       0.45      0.44      0.45       282\n",
            "           3       0.43      0.44      0.44       272\n",
            "           4       0.50      0.50      0.50       304\n",
            "           5       0.69      0.64      0.66       306\n",
            "\n",
            "    accuracy                           0.62      1742\n",
            "   macro avg       0.61      0.62      0.61      1742\n",
            "weighted avg       0.62      0.62      0.62      1742\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR8OhyplTBiz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}